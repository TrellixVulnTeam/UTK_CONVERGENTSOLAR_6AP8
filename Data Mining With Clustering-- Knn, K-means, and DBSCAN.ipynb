{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Driven Subgrouping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering Techniques\n",
    "\n",
    "## Clustering is a data driven way to groups samples of your data. Also known as unsupervised machine learning, clustering techniques are often times not guided by a set of correct predictions but must learn to make the appropriate choices through analysis of the data alone. It can be used for things such as attempting to classify objects based on the groupings, perform regression stasks by using the groupings to approximate values, as well as find hidden subgroups within your data. As with any sort of learning algorithm there are numerous variations but for today we will look at two of the main ones. \n",
    "\n",
    "### [K-Means](https://en.wikipedia.org/wiki/K-means_clustering)\n",
    "* uses the idea of \"simularity\" of data points (census tracts) to group them based on some given K averages or center points the data will be grouped around. When the algorithm begins there will be k randomly designated center points or means and each sample/census tract will be assigned to one based on which one that particular sample is closest to based on some form of distance metric such as euclidean or city block distance. After each assignment step when all samples have been assigned to a group the samples will be used to calculate the new center for the groups and then the assignment step begins again reassigning samples based on the new centers. The process continues until no more samples change groups. The idea is that if you due have data that can be clustered into groups based on the variables or factors of each sample and you choose the appropriate number of means/centers to group with you can eventually have clusters where each clusters members are far closter to each other, than they are from samples in other clusters. In this way you seek to sepereate out the data into different groups that have similar characterstics to cluster members, but different ones from members of other clusters. If this is the result you can analyze the clusters to see various things such as what characteristics are similar within each cluster to help identify what characterstics are making up the clusters. Things such as the ANOVA test you saw before can help with this.  \n",
    "\n",
    "\n",
    "### [DBSCAN](https://en.wikipedia.org/wiki/DBSCAN):\n",
    "* Unlike the KNN, DBSCAN will choose the appropriate number of groups for you. You set other hyper parameters that control how the algorithm compares samples, and it will decide the appropriate number of groupings to choose. The you must test how well these grouping differ\n",
    "\n",
    "\n",
    "### Visualization of Clustering\n",
    "\n",
    "* for simple 2-D or 3-D data you can easily visualize the clustering by coloring the values based on groupings and plotting, but as the number of dimensions in your data (variables) increases if becomes difficult to visualize purely from the data. There is a algorithm that transforms the data into what ever number of dimensions you would like and is said to appropriately still represent the data for visualization purpoes known as [TSNE](https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html) and this is another tool that will be show to you today\n",
    "\n",
    "\n",
    "### Todays Goals\n",
    "* learn about\n",
    "    * unsupervised machine learning\n",
    "    * [K-means](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html#sklearn.cluster.KMeans)\n",
    "    * [DBSCAN](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.DBSCAN.html)\n",
    "    * [TSNE](https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html)\n",
    "* Cluster you data using both KNN and DBSCAN using your current set of tested variables, \n",
    "* play around with both clustering algorithms to see how well you can get them to cluster the data\n",
    "    * look at the performance metrics described below\n",
    "    * play around with tuning the algorithm hyperparameters to see if you can improve it\n",
    "* play around with different sets of your variables to see if you can get better performance that way\n",
    "* visualize your clusterings and save some interesting ones for next time for the best performing ones\n",
    "\n",
    "* [clustering performance metrics](https://scikit-learn.org/stable/modules/classes.html?highlight=metrics#module-sklearn.metrics.cluster)\n",
    "    > * ***[Calinski-Harabasz index](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.calinski_harabasz_score.html#sklearn.metrics.calinski_harabasz_score)*** (sklearn.metrics.calinski_harabasz_score) - also known as the Variance Ratio Criterion - can be used to evaluate the model, where a ***higher Calinski-Harabasz score relates to a model with better defined clusters***. The score is defined as ratio between the within-cluster dispersion and the between-cluster dispersion.\n",
    "    \n",
    "    > * ***[Davies-Bouldin score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.davies_bouldin_score.html#sklearn.metrics.davies_bouldin_score)***(sklearn.metrics.davies_bouldin_score):The score is defined as the average similarity measure of each cluster with its most similar cluster, where similarity is the ratio of within-cluster distances to between-cluster distances. Thus, clusters which are farther apart and less dispersed will result in a better score.The minimum score is zero, with ***lower values indicating better clustering***.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Machine learning tools\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "# from sklearn.model_selection import cross_val_score, KFold\n",
    "\n",
    "# performance metrices\n",
    "from sklearn.metrics.cluster import calinski_harabasz_score, davies_bouldin_score\n",
    "\n",
    "# visualization tools\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "from time import time\n",
    "\n",
    "# Your data path\n",
    "# data_path = r'C:\\Users\\gjone\\DeepLearningDeepSolar\\_Data\\_SCALED_CLEANED_MODELS\\PaperSet_6_28_OLR_NRML_allDROP_NOIMP.xlsx'\n",
    "data_path = r'C:\\Users\\gjone\\ConvergentDataTrainer\\_Data\\ConvergentMiniEXTEND.csv'\n",
    "data_path = r'C:\\Users\\gjone\\ConvergentDataTrainer\\_Data\\__PaperSet_7_6_OLR_None_FF_.xlsx'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data_df = pd.read_excel(data_path,)\n",
    "\n",
    "data_df.head(10)\n",
    "\n",
    "#model_data = data_df.filter(items=)\n",
    "\n",
    "\n",
    "\n",
    "data_dfORIG = data_df.copy()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'# 1 Person Homes'\n",
      "'# 2 Person Homes'\n",
      "'# 3 Person Homes'\n",
      "'# 4 Person Homes'\n",
      "'# CarPool rate'\n",
      "'# Households'\n",
      "'# Transpo Bike'\n",
      "'% 1 Person Homes'\n",
      "'% 2 Person Homes'\n",
      "'% 3 Person Homes'\n",
      "'% 4 Person Homes'\n",
      "'% Green_Travelers'\n",
      "'% Some College > 25yrs'\n",
      "'AL'\n",
      "'AR'\n",
      "'AZ'\n",
      "'Age_Median'\n",
      "'Asian_Pop'\n",
      "'Asian_pct'\n",
      "'Average_Commute'\n",
      "'Average_Household_Size'\n",
      "'Avg_Monthly_Consumption_kwh'\n",
      "'BS_or_ABOVE_rate'\n",
      "'BS_rate'\n",
      "'Black_AA'\n",
      "'Black_pct'\n",
      "'CA'\n",
      "'CO'\n",
      "'CT'\n",
      "'Climate_Zone'\n",
      "'College_Edu'\n",
      "'Commutes__40min_%'\n",
      "'Cooling_Degree_Days'\n",
      "'Cooling_Degree_Days_std'\n",
      "'DC'\n",
      "'DE'\n",
      "'Daily_Solar_Radiation'\n",
      "'DeepSolar_HighSolar'\n",
      "'Dem_Rep_Ratio_2012E'\n",
      "'Energy_Cost($/kWh)'\n",
      "'Energy_Cost_x_Consumption'\n",
      "'Estimated_Yearly_savings_$'\n",
      "'FL'\n",
      "'Fam_Med_Income'\n",
      "'Families_in_Poverty'\n",
      "'Family_Household_rate'\n",
      "'Female_%'\n",
      "'Female_Pop'\n",
      "'GA'\n",
      "'Gender_Ratio'\n",
      "'Has_Net_metering'\n",
      "'Has_Property_tax'\n",
      "'Heating_Degree_Days'\n",
      "'Heating_Degree_Days_std'\n",
      "'HighIncome_own_energy_cost'\n",
      "'High_Solar_Areas'\n",
      "'Hispanic_Pop'\n",
      "'Hispanic_pct'\n",
      "'Home_owner_rt'\n",
      "'Homes Built after 2000 rate'\n",
      "'Hot_Spots_AvgArea'\n",
      "'Hot_Spots_HomeOwn'\n",
      "'Hot_Spots_hh'\n",
      "'Household_Count'\n",
      "'Household_Med_value'\n",
      "'IA'\n",
      "'ID'\n",
      "'IL'\n",
      "'IN'\n",
      "'Inc_x_Consmpt_kwh'\n",
      "'Income_Diversity'\n",
      "'Income_x_%College_Edu'\n",
      "'Income_x_Consumption_x_Cost'\n",
      "'Income_x_EnergyCost'\n",
      "'Income_x_Suitable_m2'\n",
      "'Installations_per_Household'\n",
      "'KS'\n",
      "'KY'\n",
      "'LA'\n",
      "'LowIncome_own_energy_cost'\n",
      "'Low_Commute_Times'\n",
      "'Low_Solar_Areas'\n",
      "'MA'\n",
      "'MD'\n",
      "'ME'\n",
      "'MI'\n",
      "'MN'\n",
      "'MO'\n",
      "'MS'\n",
      "'MT'\n",
      "'Male_%'\n",
      "'Male_Pop'\n",
      "'Median_Household_income'\n",
      "'Mid West'\n",
      "'ModIncome_own_energy_cost'\n",
      "'NC'\n",
      "'ND'\n",
      "'NE'\n",
      "'NH'\n",
      "'NJ'\n",
      "'NM'\n",
      "'NT3'\n",
      "'NV'\n",
      "'NY'\n",
      "'NorthEast'\n",
      "'OH'\n",
      "'OK'\n",
      "'OR'\n",
      "'Ownership_x_TotOK_Rcnt'\n",
      "'Ownership_x_TotOK_Rm2'\n",
      "'Ownership_x_TotOK_cnt'\n",
      "'PA'\n",
      "'PhD_Rate'\n",
      "'Policy_Combo'\n",
      "'Pop_25>_SomeCollege_More'\n",
      "'Popden_x_TotOK_RCnt'\n",
      "'Popden_x_TotOK_Rm2'\n",
      "'Popden_x_TotOK_cnt'\n",
      "'Population_Density'\n",
      "'Public_Transpo_Rate'\n",
      "'RI'\n",
      "'Racial_Diversity'\n",
      "'Rural'\n",
      "'Rural_Diversity'\n",
      "'SC'\n",
      "'SD'\n",
      "'Savings_potential'\n",
      "'South'\n",
      "'State_Based_Solar_Prod'\n",
      "'Suburban'\n",
      "'Suburban_Diversity'\n",
      "'T3'\n",
      "'TN'\n",
      "'TX'\n",
      "'Total_Owned_EnergyCost'\n",
      "'Total_Owned_OK_Roof_Cnt'\n",
      "'Total_own_MW'\n",
      "'Total_owned_Sbldg'\n",
      "'Total_owned_households'\n",
      "'Travel_time_10_19_rate'\n",
      "'Travel_time_20_29_rate'\n",
      "'Travel_time_20_39_rate'\n",
      "'Travel_time_30_39_rate'\n",
      "'Travel_time_40_59_rate'\n",
      "'Travel_time_less_10'\n",
      "'UT'\n",
      "'Unnamed: 0'\n",
      "'Urban'\n",
      "'Urban_Diversity'\n",
      "'VA'\n",
      "'VT'\n",
      "'VeryLowIncome_owned_energy_cost'\n",
      "'Voting_Dem_2012_rate'\n",
      "'Voting_Rep_2012_rate'\n",
      "'WA'\n",
      "'WI'\n",
      "'WV'\n",
      "'WY'\n",
      "'Walk_Commute_Rate'\n",
      "'West'\n",
      "'WestNT3'\n",
      "'White_Pop'\n",
      "'White_pct'\n",
      "'Work_From_Home_rate'\n",
      "'Yr_own_mwh'\n",
      "'Yrl_%_inc'\n",
      "'avg_monthly_bill_dlrs'\n",
      "'lowincome_tax_credit_bin'\n",
      "'total_Owned_OK_Roof_m2'\n",
      "'travel_time_60_89_rate'\n"
     ]
    }
   ],
   "source": [
    "for v in sorted(data_dfORIG.columns.tolist()):\n",
    "    print(\"'{}'\".format(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Imputaton:  (59052, 170)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Income_x_EnergyCost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>7588.936933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5547.918385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>7061.118753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>9438.881134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>9017.289466</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Income_x_EnergyCost\n",
       "0          7588.936933\n",
       "1          5547.918385\n",
       "2          7061.118753\n",
       "3          9438.881134\n",
       "4          9017.289466"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working Model:  (58921, 1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# useful for showin the columns\n",
    "#for v in sorted(data_df.columns.tolist()):\n",
    "#    print(\"'{}',\".format(v))\n",
    "\n",
    "# remove all columns in checklist that \n",
    "# have only zero values\n",
    "def remove_allone(df, checklist):\n",
    "    for c in checklist:\n",
    "        if c in df.columns.tolist():\n",
    "            if df.loc[df[c] > 0, :].shape[0] == 0:\n",
    "                df.drop(columns=[c], inplace=True)\n",
    "    return df\n",
    "    \n",
    "\n",
    "    \n",
    "# your list of predictors/independent variables\n",
    "usecols = [\n",
    "'Total residential solar installations ',   # 0\n",
    "'Adoption',                                 # 1    \n",
    "\n",
    "'# >= 25 years of age ',\n",
    "'# 2 personhouseholds',\n",
    "'# Homeowners costs > $1k.1',\n",
    "'# Homeowner',\n",
    "'Gender_(female)',\n",
    "# 'Hot_Spots_hh',\n",
    "'Nonresidential Panel Area',\n",
    "'Total RPV roof tops',\n",
    "'Total number of households',\n",
    "'popden_x_TotOK_RCnt',\n",
    "'popden_x_TotOK_Rm2',\n",
    "'Daily_solar_radiation',\n",
    "'PopulationDdensity',\n",
    "'Median_Household_income',\n",
    "'Income_x_EnergyCost',\n",
    "'Heating_degree_day_std',\n",
    "'Family Income',\n",
    "'Gender (Male)',\n",
    "'Bachelors #',\n",
    "'# Some college or More',\n",
    "'# Nonresidential State Inc',\n",
    "'# Housing Units',\n",
    "'Heating Source Coal (%)',\n",
    "'Cooling_degree_days_std',\n",
    "# 'High_Solar_Areas',  \n",
    "\n",
    "#  'Hot_Spots_AvgAr',\n",
    " 'Housing unit count',\n",
    " \n",
    "'Total Area',\n",
    "'% Admin Occu',\n",
    "'% Agriculture Occu',\n",
    "'% Arts Occu',\n",
    "\n",
    " '% Information Occu',\n",
    " '% Owner Occupied',\n",
    " '% Working from home',\n",
    "# 'DS_HighSolar',\n",
    "\n",
    " 'Cooling_degree_days',\n",
    "'Median Age',\n",
    "]\n",
    "\n",
    "\n",
    "# the states you want to use\n",
    "my_states = [\n",
    "    'al', \n",
    "    'ar', \n",
    "    'fl', \n",
    "    'ga', \n",
    "     'ky', \n",
    "     'la', \n",
    "     'ms',\n",
    "     'nc', \n",
    "     'ok', \n",
    "     'sc', \n",
    "     'tn', \n",
    "     'tx', \n",
    "     'va', \n",
    "    'wv',  \n",
    "]\n",
    "\n",
    "data_dfORIG = data_df.copy()\n",
    "\n",
    "\n",
    "# get a list of your 2 targets\n",
    "targets_l = usecols[:2]\n",
    "\n",
    "\n",
    "# make a list of only the features\n",
    "features_only = usecols[2:]\n",
    "\n",
    "# make a list of all the features and \n",
    "features = usecols[2:]  \n",
    "\n",
    "# use only your selected state data\n",
    "# data_df = data_df.loc[data_df['State'].isin(my_states), :]\n",
    "\n",
    "\n",
    "# data_df.drop(columns=['State'], inplace=True)\n",
    "\n",
    "print(\"Before Imputaton: \", data_df.shape)\n",
    "# use only your selected features\n",
    "Wmodel_data = data_df.filter(items=features+targets_l)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#  get a cleaned working model\n",
    "# this way if you mess this one up just rerun this cell\n",
    "Wmodel_data = Wmodel_data.dropna()\n",
    "\n",
    "\n",
    "display(Wmodel_data.head())\n",
    "print(\"Working Model: \", Wmodel_data.shape)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'State'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\gjone\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2896\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2897\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2898\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'State'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-197fbe0e363b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'Solar_installations_per_household'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmet_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mstate\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_dfORIG\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'State'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mmet_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_dfORIG\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdata_dfORIG\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'State'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\gjone\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2978\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2979\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2980\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2981\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2982\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\gjone\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2897\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2898\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2899\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2900\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2901\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'State'"
     ]
    }
   ],
   "source": [
    "target = 'Total residential solar installations '\n",
    "target = 'Solar_installations_per_home_owner'\n",
    "target = 'Solar_installations_per_household'\n",
    "met_dict = {}\n",
    "for state in data_dfORIG['State'].unique():\n",
    "    met_dict[state] = data_dfORIG.loc[data_dfORIG['State'] == state, target ].mean()\n",
    "\n",
    "# print(met_dict)\n",
    "met_dict = dict(sorted(met_dict.items(), key=lambda x: x[1],))\n",
    "    \n",
    "for state in met_dict: \n",
    "    print(\"{}: {:.3f}\".format(state, met_dict[state]))\n",
    "\n",
    "fontdict = {\n",
    "                'family': 'serif',\n",
    "                'style': 'normal',\n",
    "                #'variant': 'normal',\n",
    "                #'weight': 'bold',\n",
    "                #'size': 'large',\n",
    "                'size': 20,\n",
    "            }\n",
    "fontdict_Labels = {\n",
    "                'family': 'serif',\n",
    "                'style': 'normal',\n",
    "                'variant': 'normal',\n",
    "                'weight': 'bold',\n",
    "                #'size': 'large',\n",
    "                'size': 30,\n",
    "            }\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "fig, ax = plt.subplots(1, figsize=(30, 30))\n",
    "ax.barh(list(range(len(met_dict))),list(met_dict.values()), height=.5)\n",
    "\n",
    "ax.set_yticklabels([ c.upper()  for c in list(met_dict.keys())], fontdict=fontdict)\n",
    "ax.set_yticks(range(len(met_dict)))\n",
    "ax.set_xlabel(\"Average Roof Top Solar Installations per Household by State\".format(target), fontdict=fontdict_Labels)\n",
    "ax.set_title(\"Average Roof Top Solar Installations per Household by State\".format(target), fontdict=fontdict_Labels)\n",
    "ax.set_ylim((-.5, len(met_dict)+.5))\n",
    "cnt = 0\n",
    "for c in met_dict:\n",
    "    val = met_dict[c]\n",
    "    m = 1\n",
    "    while np.around(val, 0) < 1:\n",
    "        m = m*10\n",
    "        val = val*m\n",
    "    val = np.around(val, 0)\n",
    "    m *= 10\n",
    "    # width, height\n",
    "    ax.text(met_dict[c], cnt-.2, \"{}/{}\".format(int(val), m), fontdict={'size':20})\n",
    "    cnt += 1\n",
    "    \n",
    "ax.text(0, 10, \"hi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# set up your data for clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Select your target/dependent \n",
    "target = targets_l[0]\n",
    "\n",
    "\n",
    "# do you want to only use the independent variables or do you want to use them and your dependent variable\n",
    "# \n",
    "\n",
    "use_independent=False\n",
    "\n",
    "if use_independent:\n",
    "    X_vars = features_only\n",
    "else:\n",
    "    X_vars = features_only + [target]\n",
    "\n",
    "\n",
    "\n",
    "Xo = Wmodel_data.filter(items=X_vars)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create learning and vislualization tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "machine learning  and visualizations tools created\n",
      "DBSCAN failed to generate clusters\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['% Information Occu', 'Median HH Income', '# >= 25 years of age ', '# Housing Units', 'Gender_(female)', '% Admin Occu', '# Homeowners costs > $1k.1', 'Median Age', '% Owner Occupied', '# 2 personhouseholds', 'Family Income', 'Gender (Male)', '% Agriculture Occu', 'Total Area', 'Daily_solar_radiation', '# Homeowner', '# Nonresidential State Inc', 'Bachelors #', 'Housing unit count', 'Heating_degree_day_std', 'Total residential solar installations ', 'PopulationDdensity', 'Cooling_degree_days_std', 'Total number of households', 'Heating Source Coal (%)', '% Working from home', '# Some college or More', 'Cooling_degree_days', 'Total RPV roof tops', '% Arts Occu', 'Nonresidential Panel Area', 'popden_x_TotOK_RCnt', 'popden_x_TotOK_Rm2'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-608f0d61593d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 91\u001b[1;33m \u001b[0mkmu_chs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkmu_dbs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcalinski_harabasz_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXo\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mX_vars\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mXo\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'cluster-kmu'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdavies_bouldin_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXo\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mX_vars\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mXo\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'cluster-kmu'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"K-means cluster scores:\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"calinski_harabasz_score: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkmu_chs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\gjone\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2984\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2985\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2986\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2987\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2988\u001b[0m         \u001b[1;31m# take() does not accept boolean indexers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\gjone\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[1;34m(self, obj, axis, is_setter, raise_missing)\u001b[0m\n\u001b[0;32m   1283\u001b[0m                 \u001b[1;31m# When setting, missing keys are not allowed, even with .loc:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1284\u001b[0m                 \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"raise_missing\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mTrue\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mis_setter\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1285\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1286\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1287\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\gjone\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[1;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1090\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1091\u001b[0m         self._validate_read_indexer(\n\u001b[1;32m-> 1092\u001b[1;33m             \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1093\u001b[0m         )\n\u001b[0;32m   1094\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\gjone\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[1;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1183\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"loc\"\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1184\u001b[0m                 \u001b[0mnot_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1185\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{} not in index\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnot_found\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1186\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1187\u001b[0m             \u001b[1;31m# we skip the warning on Categorical/Interval\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['% Information Occu', 'Median HH Income', '# >= 25 years of age ', '# Housing Units', 'Gender_(female)', '% Admin Occu', '# Homeowners costs > $1k.1', 'Median Age', '% Owner Occupied', '# 2 personhouseholds', 'Family Income', 'Gender (Male)', '% Agriculture Occu', 'Total Area', 'Daily_solar_radiation', '# Homeowner', '# Nonresidential State Inc', 'Bachelors #', 'Housing unit count', 'Heating_degree_day_std', 'Total residential solar installations ', 'PopulationDdensity', 'Cooling_degree_days_std', 'Total number of households', 'Heating Source Coal (%)', '% Working from home', '# Some college or More', 'Cooling_degree_days', 'Total RPV roof tops', '% Arts Occu', 'Nonresidential Panel Area', 'popden_x_TotOK_RCnt', 'popden_x_TotOK_Rm2'] not in index\""
     ]
    }
   ],
   "source": [
    "# create DBSCAN tool\n",
    "DB_clster = DBSCAN(eps=.1,              #The maximum distance between two samples for one to be considered as in the neighborhood of the other.\n",
    "                   min_samples=200,        # minimum number of neighbors to look at to make a cluster high == larger cluster often\n",
    "                   metric='euclidean',  \n",
    "                   # algorithm='auto', \n",
    "                   algorithm='ball_tree',\n",
    "                   leaf_size=10,\n",
    "                   p=None, \n",
    "                   n_jobs=None)\n",
    "\n",
    "\n",
    "\n",
    "# create KMeans tool\n",
    "kmu_clster = KMeans(\n",
    "       n_clusters=8, \n",
    "       init='k-means++', \n",
    "       n_init=10, \n",
    "       max_iter=300, \n",
    "       tol=0.0001, \n",
    "       verbose=0, \n",
    "       random_state=None, \n",
    "       copy_x=True, \n",
    "       algorithm='auto',\n",
    "      \n",
    "        )\n",
    "\n",
    "\n",
    "# create TSNE visualization tool\n",
    "tsne_viz_2D = TSNE(\n",
    "                n_components=2,\n",
    "                perplexity=30.0, \n",
    "                early_exaggeration=12.0, \n",
    "                learning_rate=200.0, \n",
    "                n_iter=1000, \n",
    "                n_iter_without_progress=300, \n",
    "                min_grad_norm=1e-07, \n",
    "                metric='euclidean', \n",
    "                init='random', \n",
    "                verbose=0, \n",
    "                random_state=None, \n",
    "                method='barnes_hut', \n",
    "                angle=0.5, \n",
    "                n_jobs=None, )\n",
    "\n",
    "# create TSNE visualization tool\n",
    "tsne_viz_3D = TSNE(\n",
    "                n_components=3,\n",
    "                perplexity=30.0, \n",
    "                early_exaggeration=12.0, \n",
    "                learning_rate=200.0, \n",
    "                n_iter=1000, \n",
    "                n_iter_without_progress=300, \n",
    "                min_grad_norm=1e-07, \n",
    "                metric='euclidean', \n",
    "                init='random', \n",
    "                verbose=0, \n",
    "                random_state=None, \n",
    "                method='barnes_hut', \n",
    "                angle=0.5, \n",
    "                n_jobs=None, )\n",
    "\n",
    "print(\"machine learning  and visualizations tools created\")\n",
    "\n",
    "# use DBscan to cluster the data and get the cluster assignements\n",
    "# fit them to do the clustering\n",
    "DB_clster.fit(Xo)\n",
    "kmu_clster.fit(Xo)\n",
    "\n",
    "# get the cluster labels\n",
    "db_labels = DB_clster.labels_\n",
    "kmu_labels = kmu_clster.labels_\n",
    "\n",
    "\n",
    "# add them to your working data\n",
    "Xo['cluster-db'] = db_labels\n",
    "Xo['cluster-kmu'] = kmu_labels\n",
    "\n",
    "# \n",
    "if len(Xo['cluster-db'].unique()) > 1:\n",
    "    # attempt to score them:\n",
    "    # calinski_harabasz_score, davies_bouldin_score\n",
    "    db_chs, db_dbs = calinski_harabasz_score(Xo[X_vars], Xo['cluster-db']), davies_bouldin_score(Xo[X_vars], Xo['cluster-db'])\n",
    "    print(\"DB cluster scores:\")\n",
    "    print(\"calinski_harabasz_score: \", db_chs)\n",
    "    print(\"davies_bouldin_score: \", db_dbs)\n",
    "else:\n",
    "    db_chs, db_dbs = -1, -1\n",
    "    print(\"DBSCAN failed to generate clusters\")\n",
    "\n",
    "    \n",
    "kmu_chs, kmu_dbs = calinski_harabasz_score(Xo[X_vars], Xo['cluster-kmu']), davies_bouldin_score(Xo[X_vars], Xo['cluster-kmu'])    \n",
    "print(\"K-means cluster scores:\")\n",
    "print(\"calinski_harabasz_score: \", kmu_chs)\n",
    "print(\"davies_bouldin_score: \", kmu_dbs)  \n",
    "\n",
    "\n",
    "# lets look at the number of labels\n",
    "print(Xo['cluster-db'].unique())\n",
    "print(Xo['cluster-kmu'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methods for the tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a dictionary for the different cluster groups so each as a color\n",
    "\n",
    "def get_cluster_colors(labels, colors):\n",
    "    # get the unique values\n",
    "    allcluster = list(set(labels))\n",
    "    print(allcluster)\n",
    "    allcolr = {c:clr for c, clr in zip(allcluster, colors)}\n",
    "    # remove the non labeled colors\n",
    "    if -1 in allcolr:\n",
    "        del allcolr[-1]\n",
    "    return allcolr\n",
    "\n",
    "def plot_clusters(xtsne, labels, color_dict, fontdict=None, s=800, title=\"Cluster Plot\", figsize=(20,20)):\n",
    "    if fontdict is None:\n",
    "        fontdict = {\n",
    "                'family': 'serif',\n",
    "                'style': 'normal',\n",
    "                'variant': 'normal',\n",
    "                'weight': 'bold',\n",
    "                #'size': 'large',\n",
    "                'size': 60,\n",
    "                }\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    cnt = 0\n",
    "    for pnt in  xtsne:\n",
    "        # print(pnt)\n",
    "        if labels[cnt] >= 0:\n",
    "            ax.scatter(pnt[0], pnt[1], c=color_dict[labels[cnt]], s=s)\n",
    "        cnt += 1\n",
    "\n",
    "    #ax.invert_yaxis()  # labels read top-to-bottom\n",
    "\n",
    "    ax.set_title(title, fontdict=fontdict)\n",
    "    ax.set_facecolor(\"whitesmoke\")\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "def plot_clusters3D(xtsne, labels, color_dict, fontdict=None, s=800, title=\"Cluster Plot\", figsize=(20,20)):\n",
    "    if fontdict is None:\n",
    "        fontdict = {\n",
    "                'family': 'serif',\n",
    "                'style': 'normal',\n",
    "                'variant': 'normal',\n",
    "                'weight': 'bold',\n",
    "                #'size': 'large',\n",
    "                'size': 60,\n",
    "                }\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    cnt = 0\n",
    "    for pnt in xtsne:\n",
    "        # print(pnt)\n",
    "        if labels[cnt] >= 0:\n",
    "            ax.scatter(pnt[0], pnt[1], pnt[2], c=color_dict[labels[cnt]], s=s)\n",
    "        cnt += 1\n",
    "    #ax.invert_yaxis()  # labels read top-to-bottom\n",
    "    ax.set_title(title, fontdict=fontdict)\n",
    "    ax.set_facecolor(\"whitesmoke\")\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# list of colors to be \"mostly\" be randomly assigned to cluster\n",
    "# from the DBSCAN/kmeans\n",
    "colors = [\n",
    "    'b',\n",
    "    'r',\n",
    "    'g',\n",
    "    'c',\n",
    "    'm',\n",
    "    'y',\n",
    "    'darkblue',\n",
    "    'orange',\n",
    "    'gray',\n",
    "    'khaki',\n",
    "    'coral',\n",
    "    'darkviolet',\n",
    "    'darkgreen',\n",
    "    'lime',\n",
    "    'indigo',\n",
    "    'bisque',\n",
    "    'lavender',\n",
    "    'gold',\n",
    "    'purple',\n",
    "    'firebrick',\n",
    "    'black',\n",
    "    'seagreen',\n",
    "    'slateblue',\n",
    "    'royalblue',\n",
    "    'cornflowerblue',\n",
    "]\n",
    "\n",
    "\n",
    "colors += list(np.random.choice(list(mcolors.CSS4_COLORS.keys()), len(mcolors.CSS4_COLORS.keys()), replace=False))\n",
    "\n",
    "\n",
    "db_cluster_colors = get_cluster_colors(Xo['cluster-db'], colors)\n",
    "kmu_cluster_colors = get_cluster_colors(Xo['cluster-kmu'], colors)\n",
    "\n",
    "\n",
    "print(db_cluster_colors)\n",
    "print(kmu_cluster_colors)\n",
    "\n",
    "print(\"running tsne\")\n",
    "# fit your data using the TSNE algorithm to compress it into only N-dimensions\n",
    "db_2d = tsne_viz_2D.fit_transform(Xo)\n",
    "db_3d = tsne_viz_3D.fit_transform(Xo)\n",
    "\n",
    "\n",
    "kmu_2d = tsne_viz_2D.fit_transform(Xo)\n",
    "kmu_3d = tsne_viz_3D.fit_transform(Xo)\n",
    "\n",
    "fontdict2 = {\n",
    "                'family': 'serif',\n",
    "                'style': 'normal',\n",
    "                'variant': 'normal',\n",
    "                'weight': 'bold',\n",
    "                #'size': 'large',\n",
    "                'size': 60,\n",
    "            }                           \n",
    "                           \n",
    "\n",
    "print(\"visualizations set up\")                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# db_2dx = tsne_viz_2D.transform()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2D plots of the clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now lets try to plot them in 2d \n",
    "\n",
    "if len(Xo['cluster-db'].unique()) == 1 and -1 in Xo['cluster-db'].unique():\n",
    "    pass\n",
    "else:\n",
    "    print(\"plotting the DBSCAN generated clusters\")\n",
    "    plot_clusters(db_2d, Xo['cluster-db'].values.tolist(), db_cluster_colors, fontdict=fontdict2, s=800, title=\"Cluster Plot-DB\", figsize=(20,20))\n",
    "\n",
    "print(\"Plotting the Kmeans clusters\")\n",
    "\n",
    "plot_clusters(kmu_2d, Xo['cluster-kmu'].values.tolist(), kmu_cluster_colors, fontdict=fontdict2, s=800, \n",
    "                  title=\"Cluster Plot-KMU\", figsize=(20,20))       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3D plots of the clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if len(Xo['cluster-db'].unique()) == 1 and -1 in Xo['cluster-db'].unique():\n",
    "    pass\n",
    "else:\n",
    "    print(\"plotting the DBSCAN generated clusters\")\n",
    "    plot_clusters3D(db_3d, Xo['cluster-db'].values.tolist(), db_cluster_colors, fontdict=fontdict2, s=800, title=\"Cluster Plot-DB\", figsize=(20,20))\n",
    "\n",
    "print(\"Plotting the Kmueans clusters\")\n",
    "plot_clusters3D(kmu_3d, Xo['cluster-kmu'].values.tolist(),kmu_cluster_colors, fontdict=fontdict2, s=800, \n",
    "                  title=\"Cluster Plot-KMU\", figsize=(20,20))     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
